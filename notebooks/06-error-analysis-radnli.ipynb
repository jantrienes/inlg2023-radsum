{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast \n",
    "import unittest\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append('../ifcc/')\n",
    "sys.path.append('../ifcc/tests/')\n",
    "sys.path.append('../guidedsum/')\n",
    "\n",
    "from test_nli import TestSimpleNLI\n",
    "from annotation_utils import expand_to_borders, Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_span_annotation(row):\n",
    "    lst = row['annotations']\n",
    "\n",
    "    lst_annotations = []\n",
    "\n",
    "    for l in lst:\n",
    "        a = Annotation(start=l['start'], end=l['end'], label=list(row['majority_vote'].keys())[0], annotator='majority', document_id=row['study_id'])\n",
    "        lst_annotations.append(a)\n",
    "    \n",
    "    majority_annotion = expand_to_borders(lst_annotations)[0]\n",
    "    span_indices = {\n",
    "        'start' : majority_annotion.start,\n",
    "        'end' : majority_annotion.end\n",
    "    }\n",
    "    span = row['candidate'][majority_annotion.start:majority_annotion.end]\n",
    "    return span, span_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXTEND    186\n",
       "ACCEPT     76\n",
       "REVIEW     33\n",
       "Name: annotation_kind, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_additions = pd.read_json('../error-analysis/annotations/additions.jsonl', lines=True)\n",
    "df_additions['majority_vote'] = df_additions['majority_vote'].apply(Counter)\n",
    "df_additions['annotation_kind'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>candidate_name</th>\n",
       "      <th>annotations</th>\n",
       "      <th>annotation_kind</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>reference</th>\n",
       "      <th>candidate</th>\n",
       "      <th>findings+bg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50178679</td>\n",
       "      <td>wgsum</td>\n",
       "      <td>[{'annotator': 'annotator4', 'end': 65, 'start...</td>\n",
       "      <td>EXTEND</td>\n",
       "      <td>{'2a': 1}</td>\n",
       "      <td>No acute cardiopulmonary process based on this...</td>\n",
       "      <td>no definite acute cardiopulmonary process give...</td>\n",
       "      <td>History:\\n_-year-old female with fever and cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50296389</td>\n",
       "      <td>wgsum+cl</td>\n",
       "      <td>[{'annotator': 'annotator1', 'end': 96, 'start...</td>\n",
       "      <td>EXTEND</td>\n",
       "      <td>{'2a': 1}</td>\n",
       "      <td>Improving right hydropneumothorax with right l...</td>\n",
       "      <td>decreased though persistent right-sided hydrop...</td>\n",
       "      <td>Indication:\\nPatient with collapsed right in s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50394941</td>\n",
       "      <td>bertabs</td>\n",
       "      <td>[{'annotator': 'annotator1', 'end': 118, 'star...</td>\n",
       "      <td>EXTEND</td>\n",
       "      <td>{'2a': 1}</td>\n",
       "      <td>ET tube ends 2.5 cm above the carina, and coul...</td>\n",
       "      <td>endotracheal tube ends approximately 2.5 cm ab...</td>\n",
       "      <td>Indication:\\n_-year-old, unresponsive man stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50394941</td>\n",
       "      <td>bertabs</td>\n",
       "      <td>[{'annotator': 'annotator2', 'end': 182, 'star...</td>\n",
       "      <td>EXTEND</td>\n",
       "      <td>{'2a': 1}</td>\n",
       "      <td>ET tube ends 2.5 cm above the carina, and coul...</td>\n",
       "      <td>endotracheal tube ends approximately 2.5 cm ab...</td>\n",
       "      <td>Indication:\\n_-year-old, unresponsive man stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50394941</td>\n",
       "      <td>bertabs</td>\n",
       "      <td>[{'annotator': 'annotator1', 'end': 215, 'star...</td>\n",
       "      <td>EXTEND</td>\n",
       "      <td>{'2a': 1}</td>\n",
       "      <td>ET tube ends 2.5 cm above the carina, and coul...</td>\n",
       "      <td>endotracheal tube ends approximately 2.5 cm ab...</td>\n",
       "      <td>Indication:\\n_-year-old, unresponsive man stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id candidate_name                                        annotations  \\\n",
       "0  50178679          wgsum  [{'annotator': 'annotator4', 'end': 65, 'start...   \n",
       "2  50296389       wgsum+cl  [{'annotator': 'annotator1', 'end': 96, 'start...   \n",
       "3  50394941        bertabs  [{'annotator': 'annotator1', 'end': 118, 'star...   \n",
       "4  50394941        bertabs  [{'annotator': 'annotator2', 'end': 182, 'star...   \n",
       "5  50394941        bertabs  [{'annotator': 'annotator1', 'end': 215, 'star...   \n",
       "\n",
       "  annotation_kind majority_vote  \\\n",
       "0          EXTEND     {'2a': 1}   \n",
       "2          EXTEND     {'2a': 1}   \n",
       "3          EXTEND     {'2a': 1}   \n",
       "4          EXTEND     {'2a': 1}   \n",
       "5          EXTEND     {'2a': 1}   \n",
       "\n",
       "                                           reference  \\\n",
       "0  No acute cardiopulmonary process based on this...   \n",
       "2  Improving right hydropneumothorax with right l...   \n",
       "3  ET tube ends 2.5 cm above the carina, and coul...   \n",
       "4  ET tube ends 2.5 cm above the carina, and coul...   \n",
       "5  ET tube ends 2.5 cm above the carina, and coul...   \n",
       "\n",
       "                                           candidate  \\\n",
       "0  no definite acute cardiopulmonary process give...   \n",
       "2  decreased though persistent right-sided hydrop...   \n",
       "3  endotracheal tube ends approximately 2.5 cm ab...   \n",
       "4  endotracheal tube ends approximately 2.5 cm ab...   \n",
       "5  endotracheal tube ends approximately 2.5 cm ab...   \n",
       "\n",
       "                                         findings+bg  \n",
       "0  History:\\n_-year-old female with fever and cou...  \n",
       "2  Indication:\\nPatient with collapsed right in s...  \n",
       "3  Indication:\\n_-year-old, unresponsive man stat...  \n",
       "4  Indication:\\n_-year-old, unresponsive man stat...  \n",
       "5  Indication:\\n_-year-old, unresponsive man stat...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_additions.groupby(['study_id', 'candidate_name']).size().rename('number of additions').reset_index()\n",
    "df_filtered = df_additions[\n",
    "    (df_additions['majority_vote'].apply(lambda x: x['2a'] >= 1 and len(x.keys()) == 1)) &\n",
    "    ((df_additions['annotation_kind'] == 'ACCEPT') | (df_additions['annotation_kind'] == 'EXTEND'))]\n",
    "df_filtered = df_filtered.copy()\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_spans = []\n",
    "majority_annotations = []\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    span, annotation = get_majority_span_annotation(row)\n",
    "    majority_spans.append(span)\n",
    "    majority_annotations.append(annotation)\n",
    "\n",
    "df_filtered['majority_span'] = majority_spans\n",
    "df_filtered['majority_annotation'] = majority_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['findings'] = df_filtered['findings+bg'].apply(lambda x: re.search(r\"^Findings:\\n(.*)\", x, flags=re.MULTILINE).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli = TestSimpleNLI()\n",
    "nli.setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007767438888549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 206,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fcef776b034680a362a41df4638154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probas = []\n",
    "preds = []\n",
    "report_sents = []\n",
    "\n",
    "for i, row in tqdm(df_filtered.iterrows(), total=len(df_filtered)):\n",
    "    x_sents = sent_tokenize(row['findings'])\n",
    "    report_sents.append(x_sents)\n",
    "    addition_expanded = [row['majority_span']]*len(x_sents)\n",
    "   \n",
    "    rs = nli.nli.predict(x_sents, addition_expanded)\n",
    "    rs_proba = rs[0]\n",
    "    rs_preds = rs[1]\n",
    "\n",
    "    probas.append(rs_proba)\n",
    "    preds.append(rs_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for p in preds:\n",
    "    if 'contradiction' in p:\n",
    "        final_preds.append('-')\n",
    "    elif 'entailment' in p:\n",
    "        final_preds.append('+')\n",
    "    else:\n",
    "        final_preds.append('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['preds_counter'] = [Counter(p) for p in preds]\n",
    "df_filtered['preds'] = preds\n",
    "df_filtered['probas'] = probas\n",
    "df_filtered['sents'] = report_sents \n",
    "df_filtered['final_pred'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+   33.01\n",
      "-   25.73\n",
      "o   41.26\n"
     ]
    }
   ],
   "source": [
    "c = Counter(final_preds)\n",
    "for k, v in c.items():\n",
    "    print(k, ' ', np.round((v*100)/len(df_filtered), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw prediction counts by method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>final_pred</th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertabs</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsum_thresholding</th>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wgsum</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wgsum+cl</th>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "final_pred          +   -   o\n",
       "candidate_name               \n",
       "bertabs            15  11  21\n",
       "gsum_thresholding  20  17  21\n",
       "wgsum              16  12  22\n",
       "wgsum+cl           17  13  21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.groupby('candidate_name')['final_pred'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and export as latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entail</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Contradict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BertAbs</th>\n",
       "      <td>31.9</td>\n",
       "      <td>44.7</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSum w/ Thresholding</th>\n",
       "      <td>34.5</td>\n",
       "      <td>36.2</td>\n",
       "      <td>29.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WGSum</th>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WGSum+CL</th>\n",
       "      <td>33.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Entail  Neutral  Contradict\n",
       "                                                 \n",
       "BertAbs                 31.9     44.7        23.4\n",
       "GSum w/ Thresholding    34.5     36.2        29.3\n",
       "WGSum                   32.0     44.0        24.0\n",
       "WGSum+CL                33.3     41.2        25.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[t]\n",
      "\\small\n",
      "\\centering\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} & \\textbf{Entail} & \\textbf{Neutral} & \\textbf{Contradict} \\\\\n",
      " & & & \\\\\n",
      "\\midrule\n",
      "BertAbs & 31.9 & 44.7 & 23.4 \\\\\n",
      "GSum w/ Thresholding & 34.5 & 36.2 & 29.3 \\\\\n",
      "WGSum & 32.0 & 44.0 & 24.0 \\\\\n",
      "WGSum+CL & 33.3 & 41.2 & 25.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_filtered.groupby('candidate_name')['final_pred'].value_counts(normalize=True).unstack()\n",
    "df = df.rename({'+': 'Entail', '-': 'Contradict', 'o': 'Neutral'}, axis=1)\n",
    "df = df.rename({\n",
    "    'bertabs': 'BertAbs',\n",
    "    'gsum_thresholding': 'GSum w/ Thresholding',\n",
    "    'wgsum': 'WGSum',\n",
    "    'wgsum+cl': 'WGSum+CL',\n",
    "}, axis=0)\n",
    "df = df[['Entail', 'Neutral', 'Contradict']]\n",
    "df.index.name = ''\n",
    "df.columns.name = ''\n",
    "df = (df * 100).round(1)\n",
    "display(df)\n",
    "\n",
    "\n",
    "tex = df.to_latex(\n",
    "    na_rep=\"-\",\n",
    "    position='t',\n",
    "    escape=False,\n",
    "    index_names=True,\n",
    "    column_format='l' + 'r' * len(df.columns), # Align: left for row label, right for all numbers\n",
    "    multicolumn_format='c',\n",
    ")\n",
    "tex = tex.replace('table', 'table*')\n",
    "tex = tex.replace('\\\\centering', '\\\\small\\n\\centering')\n",
    "# tex = tex.replace('\\centering', '\\centering\\n\\\\resizebox{\\\\textwidth}{!}{')\n",
    "# tex = tex.replace('\\end{tabular}', '\\end{tabular}}')\n",
    "tex = tex.replace('Method', '\\\\textbf{Method}')\n",
    "\n",
    "for c in df.columns:\n",
    "    tex = tex.replace(c, '\\\\textbf{' + c + '}')\n",
    "    \n",
    "tex = re.sub(r' +', ' ', tex)\n",
    "print(tex)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
